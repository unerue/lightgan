# @package _global_
defaults:
  - override /data: default
  - override /model: default
  - override /trainer: default
  - override /callbacks: default
  - override /logger: default

tags: ["cut"]
test: false

data:
  _target_: src.datasets.UnalignedDataModule
  data_dir: ${paths.data_dir}/rgb2ir
  batch_size: 1
  num_workers: 4
  pin_memory: true

model:
  _target_: src.models.CutModel
  batch_size: ${data.batch_size}
  out_channels: 3
  flip_equivariance: false
  nce_layers: [0, 4, 8, 12, 16]
  lambda_nce: 1.0
  nce_t: 0.07
  lambda_gan: 1.0
  nce_idt: true
  optimizer1:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.0002
    betas: [0.5, 0.999]
  optimizer2:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.0002
    betas: [0.5, 0.999]
  optimizer3:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.0002
    betas: [0.5, 0.999]
  scheduler1:
    _target_: src.ops.DelayedLinearDecayLR
    _partial_: true
    initial_lr: 0.0002
    target_lr: 0.0001
    decay_after: 30
    total_iters: ${trainer.max_epochs}
  scheduler2:
    _target_: src.ops.DelayedLinearDecayLR
    _partial_: true
    initial_lr: 0.0002
    target_lr: 0.0001
    decay_after: 30
    total_iters: ${trainer.max_epochs}
  scheduler3:
    _target_: src.ops.DelayedLinearDecayLR
    _partial_: true
    initial_lr: 0.0002
    target_lr: 0.0001
    decay_after: 30
    total_iters: ${trainer.max_epochs}

  image_shape: [3, 256, 256]
  compile: false

trainer:
  max_epochs: 60
  accelerator: gpu
  devices: 1
  check_val_every_n_epoch: 1
  precision: "16-mixed"
  enable_model_summary: false
  num_sanity_val_steps: 2
  fast_dev_run: false

logger:
  wandb:
    tags: ${tags}
    group: "horse2zebra"

callbacks:
  model_summary:
    max_depth: 2
